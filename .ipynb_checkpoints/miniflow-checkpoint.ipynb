{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the input node in topological order\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self,inbound_nodes=[]):\n",
    "        # node from which this node recieve the value\n",
    "        self.inbound_nodes=inbound_nodes\n",
    "        #this node pass the value to the outbound nods\n",
    "        self.outbound_nodes=[]\n",
    "        #this node hold the value\n",
    "        self.value=None\n",
    "        \n",
    "        self.gradients={}\n",
    "        # set this node as the outbound node for the inputs\n",
    "        for node in self.inbound_nodes:\n",
    "            node.outbound_nodes.append(self)\n",
    "            \n",
    "    def forward(self):\n",
    "        #this function calculate the value and assign it to the self.value\n",
    "        raise NotImplementedError\n",
    "    def backward(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        #intialize the input node as it does not recieve any inbound nodes\n",
    "        Node.__init__(self)\n",
    "        #input node is the only node which recieve value an an argument as\n",
    "        # All other node have to calculte there value from the inbounds nodes\n",
    "    def forward(self,value=None):\n",
    "        if value is not None:\n",
    "            self.value=value\n",
    "    def backward(self):\n",
    "        #input node has no input node so gradiant(derivative) is 0\n",
    "        self.gradients={self:0}\n",
    "        #Input node may have weight and biase for input node from all over the output node\n",
    "        for n in self.outbound_nodes:\n",
    "            grad_cost=n.gradients[self]\n",
    "            self.gradients[self]+=grad_cost*1\n",
    "class Add(Node):\n",
    "    def __init__(self,x,y):\n",
    "        Node.__init__(self,[x,y])\n",
    "    def forward(self):\n",
    "        # calculate the sum of the inbounds value\n",
    "        self.value=self.inbound_nodes[0].value+self.inbound_nodes[1].value\n",
    "    def backward(self):\n",
    "        pass\n",
    "    \n",
    "class Linear(Node):\n",
    "    def __init__(self,X,W,b):\n",
    "        Node.__init__(self,[X,W,b])\n",
    "    def forward(self):\n",
    "        sum=0\n",
    "        X=self.inbound_nodes[0].value\n",
    "        W=self.inbound_nodes[1].value\n",
    "        b=self.inbound_nodes[2].value\n",
    "        self.value= np.dot(X,W)+b\n",
    "    def backward(self):\n",
    "        #Intialise the partial for each of the inbound node\n",
    "        self.gradients={n:np.zeros_like(n.value) for n in self.inbound_nodes}\n",
    "#         print(self.gradiant)\n",
    "        for n in self.outbound_nodes:\n",
    "            grad_cost=n.gradients[self]\n",
    "            self.gradients[self.inbound_nodes[0]]+=np.dot(grad_cost,self.inbound_nodes[1].value.T)\n",
    "            self.gradients[self.inbound_nodes[1]]+=np.dot(self.inbound_nodes[0].value.T,grad_cost)\n",
    "            self.gradients[self.inbound_nodes[2]]+=np.sum(grad_cost,axis=0,keepdims=False)\n",
    "        \n",
    "class Sigmoid(Node):\n",
    "    def __init__(self,node):\n",
    "        Node.__init__(self,[node])\n",
    "    def _sigmoid(self,x):\n",
    "        sigmoid=1.0/(1+np.exp(-x))\n",
    "        return sigmoid\n",
    "    def forward(self):\n",
    "        inbound_nodes=self.inbound_nodes[0].value\n",
    "        self.value=self._sigmoid(inbound_nodes)\n",
    "    def backward(self):\n",
    "        self.gradients={n:np.zeros_like(n.value) for n in self.inbound_nodes}\n",
    "        for n in self.outbound_nodes:\n",
    "            grad_cost=n.gradients[self]\n",
    "            sigmoid=self.value\n",
    "            self.gradients[self.inbound_nodes[0]]+=sigmoid*(1-sigmoid)*grad_cost\n",
    "            \n",
    "        \n",
    "class MSE(Node):\n",
    "    def __init__(self,y,a):\n",
    "        Node.__init__(self,[y,a])\n",
    "    def forward(self):\n",
    "        y=self.inbound_nodes[0].value.reshape(-1,1)\n",
    "        a=self.inbound_nodes[1].value.reshape(-1,1)\n",
    "        m=self.inbound_nodes[0].value.shape[0]\n",
    "        print('shape:::',m)\n",
    "        self.m=m\n",
    "        diff=y-a\n",
    "        self.diff=diff\n",
    "        self.value=np.mean(diff**2)\n",
    "    def backward(self):\n",
    "        self.gradients[self.inbound_nodes[0]]=(2/self.m)*self.diff\n",
    "        self.gradients[self.inbound_nodes[1]]=(-2/self.m)*self.diff\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_nodes:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_nodes:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "# def forward_pass(output_node,sorted_node):\n",
    "#     #perform a forward pass through a list of the sorted node\n",
    "#     for n in sorted_node:\n",
    "#         print('forward_pass::::::::',n.value)\n",
    "#         n.forward()\n",
    "#     return output_node.value\n",
    "\n",
    "def forward_pass(graph):\n",
    "    #perform a forward pass through a list of the sorted node\n",
    "    for n in graph:\n",
    "        print('forward_pass::::::::',n.value)\n",
    "        n.forward()\n",
    "def forward_and_backward(graph):\n",
    "    \"\"\"\n",
    "    Performs a forward pass and a backward pass through a list of sorted Nodes.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `graph`: The result of calling `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    # Backward pass\n",
    "    # see: https://docs.python.org/2.3/whatsnew/section-slices.html\n",
    "    for n in graph[::-1]:\n",
    "        n.backward()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
